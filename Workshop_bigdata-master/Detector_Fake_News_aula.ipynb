{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "<a href='http://www.bigdata.com.br'> <img src=\"imagens/LogoBd.png\" width=\"300\"/></a>\n",
    "\n",
    "_____\n",
    "\n",
    "# Uma introdução a Ciência de Dados a partir das Fake News\n",
    "\n",
    "\n",
    "As *Fake News* referem-se a desinformação, ou má informação, que são disseminadas pelo boca a boca ou pela mídia tradicional e, mais recentemente, por formas digitais de comunicação, como vídeos editados, memes, anúncios não verificados e rumores propagados pelas mídias sociais. Recentemente elas se tornaram um problema sério, com o potencial de resultar em violência da multidão, suicídios etc. por causa de informações erradas circuladas nas mídias sociais.\n",
    "\n",
    "![fake news](imagens/fake_news.jpeg)\n",
    "\n",
    "Nesse notebook iremos explorar algoritimos do campo de **Processamento de Linguagem Natural** para reconhecer *Fake News*. Aqui, não vamos entrar muito a fundo na definição de Processamento de Linguagem Natural, mas é sulficiente saber que se trata de uma subárea do *Machine Learning*.\n",
    "\n",
    "## Funcionalidades básicas do Jupyter Notebook\n",
    "Cada célula do Jupyter roda um conjunto de linhas de código em python.\n",
    "Existem dois modos de rodar uma célula:\n",
    "* **Shift + Enter** para rodar a célula selecionada e ir para a próxima.\n",
    "* **Alt + Enter** para rodar a célula selecionada e criar uma em seguida.\n",
    "\n",
    "Se estiver usando o Google Colab, você pode rodar uma célula utilizando o botão *play* ao lado.\n",
    "\n",
    "\n",
    "Rode a célula a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora rode a célula abaixo, sem criar uma nova, para importar as bibliotecas utilizadas durante o workshop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "import re,string,unicodedata\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploração de dados\n",
    "Nessa parte iremos importar os dados e analisa-los, utilizando a biblioteca *pandas* exportada anteriormente:\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "Iremos utilizar um banco de dados criado por pesquisadores do NILC(Núcleo Interinstitucional de Linguística Computacional), chamado [*Fake.Br Corpus*](https://github.com/roneysco/Fake.br-Corpus).\n",
    "\n",
    "Para obtermos os dados, rode as células abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o dataset de notícias verdadeiras\n",
    "dataset_true_url=\"https://raw.githubusercontent.com/vitorhi/Workshop_bigdata/master/dataset/true.csv\"\n",
    "true=pd.read_csv(dataset_true_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o dataset de notícias falsas\n",
    "dataset_fake_url=\"https://raw.githubusercontent.com/vitorhi/Workshop_bigdata/master/dataset/fake.csv\"\n",
    "fake=pd.read_csv(dataset_fake_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, temos dois *datasets* armazenados em *dataframes* do pandas. \n",
    "\n",
    "Um chamado `true` e outro `fake` \n",
    "\n",
    "Verifique o começo do dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça o mesmo para o *dataframe* de notícias falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insira o código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos concatenar esses *dataframes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true['category'] = 1\n",
    "fake['category'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([true,fake], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que concatenamos dois *dataframes* em `df` e acrescentamos mais uma coluna. Ficando com 2 colunas: *text* e *category*.  \n",
    "A coluna *category* se comporta da seguinte maneira:\n",
    "* Caso a notícia em *text* seja **verdadeira**, *category* = 1\n",
    "* Caso a notícia em *text* seja **falsa**, *category* = 0\n",
    "\n",
    "Vamos obter uma coluna de `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a coluna *category* é muito grande, por isso não foi mostrada como um todo.   \n",
    "Podemos obter uma lista de 3 linhas utilizando a sintaxe do *python*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['category'][0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tente utilizar `print` para obter a notícia de índice 0 na coluna *text* em `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos utilizar ferramentas de visualização para explorar os dados.   \n",
    "A biblioteca *seaborn* (importada como **`sns`**) será usada para a visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica-se que há quantidades iguais de notícias falsas e verdadeiras em nossa base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos olhar algumas funções interessantes:\n",
    "###  Funções interessantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtros\n",
    "df[df['category']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça o mesmo para notícias falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Counts\n",
    "df2 = pd.DataFrame([['Cachorro', 'Serra'],['Gato', 'Martelo'],['Cachorro', 'Martelo']], columns=['Animal', 'Ferramenta'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Animal'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostre quantas notícias são falsas e quantas não são:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voltando a exploração de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos obter as *stopwords*, para depois remove-las da nossa base de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça o print das *stopwords* guardadas na variável `stop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos remover as stopwords e URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo URL's\n",
    "def remove_links(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "# Removendo stopwords do texto\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "# Executando as duas funções anteriores\n",
    "def denoise_text(text):\n",
    "    text = remove_links(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "# Aplicar funçao em cada notícia\n",
    "df['text']=df['text'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos observar quais palavras são mais comuns em cada banco de dados, fazendo um *worldcloud*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para notícias verdadeiras\n",
    "plt.figure(figsize = (20,20))\n",
    "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = stop).generate(\" \".join(df[df['category'] == 1]['text']))\n",
    "plt.imshow(wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para notícias falsas\n",
    "plt.figure(figsize = (20,20))\n",
    "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = stop).generate(\" \".join(df[df['category'] == 0].text))\n",
    "plt.imshow(wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando Sklearn\n",
    "Vamos utilizar o Sklearn para fazer uma matriz de contagem de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serie de exemplo\n",
    "pandas_string = pd.Series(['Bem vindo', 'Bem Vindo a', 'Bem Vindo a Semana da Inovação. Seja Bem vindo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o vetorizador do Sklearn com as stop words formadas antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop)\n",
    "X = vectorizer.fit_transform(pandas_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando o método toarray() para tranforma-lá em uma array python\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos realizar apenas a contagem da palavra 'Lula'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary=[\"lula\"]\n",
    "vectorizer.fit_transform(vocabulary);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realize a transdormação do dataset e a guarde na variável `X` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima os nomes das features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie uma coluna chamada `NumLula` com a contagem da palavra 'lula'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando Modelo\n",
    "### Classificação Logística\n",
    "Rode as células a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão entre dados de treino e dados de teste\n",
    "x_train,x_test,y_train,y_test = train_test_split(df['NumLula'], df['category'], test_size=0.3)\n",
    "\n",
    "# Fitting do classificador\n",
    "model = linear_model.LogisticRegression(C=1e5)\n",
    "model.fit(x_train.values.reshape(-1,1), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(x_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico da regressão \n",
    "plt.figure(1, figsize=(7, 6))\n",
    "plt.clf()\n",
    "plt.scatter(x_train.ravel(), y_train, color='black', zorder=20)\n",
    "x = np.linspace(-50, 80, 300)\n",
    "\n",
    "loss = expit(x * model.coef_ + model.intercept_).ravel()\n",
    "plt.plot(x, loss, color='red', linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusão\n",
    "Vamos introduzir o conceito de matriz de confusão:\n",
    "\n",
    "<img src=\"imagens/matriz_confusao.png\" width=\"300\"/>\n",
    "\n",
    "Faça a sua própria matriz de confusão utilizando a função `confusion_matrix()`   \n",
    "Faça o *print* da *confusion matrix* para esse modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular a precisão e outras métricas com a função `classification_report()`  \n",
    "Faça o *print* da classification report para esse modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se que:\n",
    "* Caso a notícia em *text* seja **verdadeira**, *category* = 1\n",
    "* Caso a notícia em *text* seja **falsa**, *category* = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação SVC\n",
    "Rode a célula a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df['text'], df['category'], test_size=0.3, random_state=2020)\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer(stop_words=stop)),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', LinearSVC())])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça o *print* da `confusion_matrix` e do `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima uma notícia a seguir e depois, utilizando o método `model.predict()`, preveja se a notícia é falsa ou não:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais alguns exemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_falso='Dr. Ray peita Bolsonaro, chama-o de conservador fake em entrevista a Danilo Gentili e divide a direita.\\n\\nEste site vem avisando Jair Bolsonaro que ele deveria abandonar a pauta estatista de vez e fazer um discurso mais convincente para aquela boa parte dos liberais e conservadores do Brasil que querem se ver livres das amarras estatais.\\n\\nTudo bem que as pesquisas ainda dizem que a maior parte do povo é contra as privatizações, mas o índice (pouco mais de 50% do povo) é fácil de ser revertido. Ademais, Bolsonaro deveria falar para direitistas em vez de focar tanto em petistas arrependidos.\\n\\nRecentemente ele disse que pensaria 200 vezes antes de privatizar a Petrobrás para que ela não caia nas mãos de chineses (ou algo do tipo). Deveria ter dito: Eu garanto a privatização da Petrobrás, e também garanto que chineses não irão comprá-la. Isso não deixaria brechas. Do jeito que ele falou, parece que o suposto medo de venda aos chineses é pretexto para evitar a privatização.\\n\\nSeja lá como for, a direita vai ter que adotar alternativas que foquem em um estado reduzido, diminuição de impostos e venda de estatais. Além de João Amoedo, Dr. Rey está fazendo vicejar este tipo de discurso e  ainda que sua candidatura esteja em fase inicial  é complicado para Bolsonaro que apareçam pessoas de direita propondo uma visão economicamente direitista para a economia.\\n\\nEnfim, veja aos 32:40 Dr. Rey espinafrando Bolsonaro: Quem dá brechas não pode reclamar que os outros aproveitem, não é mesmo?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peguei um texto do site do G1 do dia 14/06/2020:https://g1.globo.com/sp/sao-paulo/noticia/2020/06/14/manifestantes-fazem-ato-em-defesa-da-democracia-em-sp.ghtml\n",
    "\n",
    "E coloquei na variável a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_verdadeiro='Manifestantes fazem ato em defesa da democracia e contra Bolsonaro em SP\\n\\nManifestantes realizaram um protesto na tarde deste domingo (14) na Avenida Paulista, Centro de São Paulo, em defesa da democracia, contra o presidente Jair Bolsonaro (sem partido), e contra o racismo. A concentração do ato começou às 14h em frente ao vão livre do Museu de Arte de São Paulo (Masp).\\n\\nO grupo seguiu em caminhada pela avenida, no sentido Paraíso, até próximo à estação Brigadeiro do Metrô, onde foi feito um discurso. O ato permaneceu pacífico até o final do trajeto. Por volta das 16h, iniciou-se a dispersão.\\n\\nTrês homens que portavam símbolos nazistas foram detidos. Mas, segundo a Secretaria de Segurança Pública (SSP), eles não participavam das manifestações e estariam apenas passando pela avenida quando uma mulher os denunciou para a polícia.\\n\\nO protesto foi realizado por integrantes das torcidas de quatro times de futebol (Corinthians, Palmeiras, São Paulo e Santos), entidades estudantis, Somos Democracia, Frente Povo Sem Medo, MTST (Movimento dos Trabalhadores Sem Teto), CMP (Central de Movimentos Populares), coletivo de mulheres, entre outros movimentos sociais.\\n\\nUma faixa grande com os dizeres \"Fora Bolsonaro\" foi estendida na avenida. Outros cartazes também traziam frases contra o fascismo e racismo.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro exemplo de notícia falsa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_falso='NA ITÁLIA A CURA DO CORONAVIRUS É FINALMENTE ENCONTRADA.Os médicos italianos, desobedeceram a lei mundial da saúde da OMS, para não fazer autópsias nos mortos do Coronavírus e descobriram que NÃO é um VÍRUS, mas uma BACTERIA que causa a morte. Isso causa a formação de coágulos sanguíneos e causa a morte do paciente.TalA Itália derrota o chamado Covid-19, que nada mais é do que \"Coagulação intravascular disseminada\" (trombose).The E a maneira de combatê-lo, ou seja, sua cura, é com os “antibióticos, anti-inflamatórios e anticoagulantes”. ASPIRINA, indicando que esta doença foi mal tratada.Esta notícia sensacional para o mundo foi produzida por médicos italianos, realizando autópsias em cadáveres produzidos pelo Covid-19.OmAlgo mais, de acordo com patologistas italianos. \"Os ventiladores e a unidade de terapia intensiva nunca foram necessários.\"Portanto, na Itália começou a mudança de protocolos, ITÁLIA A pandemia global tão conhecida é revelada e ressuscitada pela OMS, essa cura que os chineses já sabiam e não relataram PARA FAZER NEGÓCIOS.Fonte: Ministério da Saúde da Itália.COMPARTILHE QUE O MUNDO SABE QUE Fomos enganados e assassinados por nossas pessoas mais velhas !!!@ italiarevelacurardel­­­­­covid19ALERTA DOS OLHOSPasse isso para toda a sua família, vizinhança, conhecidos, amigos, colegas, colegas de trabalho ... etc. etc ... e seu ambiente em geral ...:Se eles contrairem o Covid-19 ... que não é um vírus como eles nos fizeram acreditar, mas uma bactéria ... amplificada com radiação eletromagnética 5G que também produz inflamação e hipóxia.Eles farão o seguinte:Eles vão tomar aspirina 100mg e Apronax ou Paracetamol ...Por quê? ... porque foi demonstrado que o que o Covid-19 faz é coagular o sangue, fazendo com que a pessoa desenvolva uma trombose e o sangue não flua e não oxigene o coração e os pulmões e a pessoa morra rapidamente devido a não ser capaz de respirar.Na Itália, eles estragaram o protocolo da OMS e fizeram uma autópsia em um cadáver que morreu de Covid-19 ... eles cortaram o corpo e abriram os braços e pernas e as outras seções do corpo e perceberam que as veias estavam dilatadas e coaguladas sangue e todas as veias e artérias cheias de trombos, impedindo que o sangue flua normalmente e levando oxigênio a todos os órgãos, principalmente ao cérebro, coração e pulmões e o paciente acabe morrendo,Já conhecendo esse diagnóstico, o Ministério da Saúde italiano mudou imediatamente os protocolos de tratamento Covid-19 ... e começou a administrar a seus pacientes positivos Aspirina 100mg e Apraxax ..., resultado: os pacientes começaram a se recuperar e apresentar melhorias e o Ministério of Health liberou e enviou para casa mais de 14.000 pacientes em um único dia.URGENTE: transmitir essas informações e torná-las virais, aqui em nosso país eles mentiram para nós, com essa pandemia, a única coisa que nosso presidente diz todos os dias são dados e estatísticas, mas não fornecer essas informações para salvar os cidadãos, será que também será ameaçado pelas elites? ... não sabemos, de repente todos os governos do mundo, mas a Itália quebrou a norma ... porque eles já estavam sobrecarregados e em sério caos de mortes diárias ..., agora a OMS. ... seria processado em todo o mundo por encobrir tantas mortes e o colapso das economias de muitos países do mundo ... agora entende-se por que a ordem para INCINERAR ou enterrar imediatamente os corpos sem autópsia ... e os rotulou como altamente poluente.Está em nossas mãos levar a verdade e esperar salvar muitas vidas ... ESPALHE EM TODAS AS REDES URGENTES !!!!! é por isso que o gel antibacteriano funciona e o dióxido de cloro ... Toda a PANDÊMICA é porque eles querem vacinar e chutar para assassinar as massas para controlá-las e reduzir a população mundial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
